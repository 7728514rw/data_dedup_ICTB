# Unlearning Baselines Research

## SISA (Sharded, Isolated, Sliced, Aggregated)
- From: Bourtoule et al. (2021)
- Pros: Efficient unlearning by retraining only affected shards.
- Cons: Higher storage overhead; less effective in federated settings without adaptation.
- Relevance: Adapt for our FL setup to handle duplications.

## FedEraser
- From: Liu et al. (2022)
- Pros: Gradient-based unlearning in FL, preserves model utility.
- Cons: Computationally intensive for large models.
- Relevance: Test against duplication attacks in non-IID data.

Sources: ACM DL, IEEE Xplore.